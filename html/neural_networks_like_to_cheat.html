<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-12-16 Sat 01:33 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Neural networks like to "cheat"</title>
<meta name="author" content="Ketan Agrawal" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="syntax.css" />
<link rel="stylesheet" type="text/css" href="styles.css" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
<link rel="manifest" href="/site.webmanifest" />
</head>
<body>
<div id="preamble" class="status">
<header>
    <script src="setup-initial-theme.js"></script>
    <div style="display: flex; flex-direction: row; justify-content: space-between; align-items: center;">
        <a style="color: inherit; text-decoration: none" href="/">
            ketan agrawal
        </a>
        <div>
            <input type="checkbox" id="theme-switcher">
            <label id="theme-switcher-label" for="theme-switcher"></label>
        </div>
    </div>
</header>
</div>
<div id="content" class="content">
<h1 class="title">Neural networks like to &ldquo;cheat&rdquo;
<br />
<span class="subtitle">Last modified on April 08, 2022</span>
</h1>
<p>
<a href="artificial_intelligence.html#ID-ef80dd22-3ade-4fd6-98cd-1319eaa454f9">artificial intelligence</a><br />
</p>


<div id="outline-container-org3bf9ab3" class="outline-2 references">
<h2 id="org3bf9ab3">Links to &ldquo;Neural networks like to &rdquo;cheat&ldquo;&rdquo;</h2>
<div class="outline-text-2" id="text-org3bf9ab3">
</div>
<div id="outline-container-orga6f946d" class="outline-3">
<h3 id="orga6f946d"><a href="counterfactual_generative_networks.html#ID-22706d1f-6b5c-4c77-acc2-d8c222b395d5">Counterfactual Generative Networks</a></h3>
<div class="outline-text-3" id="text-orga6f946d">
<p>
<a href="neural_networks_like_to_cheat.html#ID-412cda14-f385-463d-9a7e-cd9ffe87c0a2">Neural networks like to &ldquo;cheat&rdquo;</a> by using simple correlations that fail to generalize. E.g., image classifiers can learn spurious correlations with texture in the background, rather than the actual object&rsquo;s shape; a classifier might learn that &ldquo;green grass background&rdquo; =&gt; &ldquo;cow classification.&rdquo;<br />
</p>

<p>
This work <a href="compositionality.html#ID-b6fafba6-8e57-400d-962c-bf7cc892a41f">decomposes</a> the image generation process into three independent causal mechanisms &#x2013; shape, texture, and background. Thus, one can generate &ldquo;<a href="causal_inference.html#ID-1f3f1a31-ff89-4c05-8c82-64888887f45e">counterfactual</a> images&rdquo; to improve OOD robustness, e.g. by placing a cow on a swimming pool background. Related: <a href="private/20200928215821-psych_204.html#ID-8e87ac0e-1002-474e-b4e7-778d908270a6">generative models</a> <a href="causal_inference.html#ID-1f3f1a31-ff89-4c05-8c82-64888887f45e">counterfactuals</a><br />
</p>
</div>
</div>

<div id="outline-container-org954e0da" class="outline-3">
<h3 id="org954e0da"><a href="cs224u_natural_language_understanding.html#ID-4785205d-bb3f-4795-9b13-7bc8128e3ae0">CS224u: Natural Language Understanding</a> <span class="backlinks-outline-path">(<i>Introduction &gt; Limitations</i>)</span></h3>
<div class="outline-text-3" id="text-org954e0da">
<ul class="org-ul">
<li>NLU systems are easily &ldquo;confused.&rdquo;<br /></li>
<li>Models don&rsquo;t &ldquo;know what the world is like.&rdquo; e.g., GPT-3 doesn&rsquo;t really&#x2026;know what a cat is. Image-captioning models show that they don&rsquo;t know what the world is like.<br /></li>
<li>Systems can encourage self-harm.<br /></li>
<li>Systems are vulnerable to adversarial attacks.<br /></li>
<li>Social biases are reflected in NLP models.<br /></li>
<li>Observing diminishing returns in ever-larger language models.<br /></li>
<li><a href="neural_networks_like_to_cheat.html#ID-412cda14-f385-463d-9a7e-cd9ffe87c0a2">Neural networks like to &ldquo;cheat&rdquo;.</a> NLI models figure out how to predict the correct relation between premise-hypothesis through some superficial correlation.<br /></li>
</ul>

<p>
Question someone asked: &ldquo;Is there any case where symbolic approaches definitely would be used over neural nets?&rdquo;<br />
</p>

<p>
Answer: Mental health chatbot. Don&rsquo;t want it saying harmful things to users. Other safety-critical situations. etc. Also&#x2013; sometimes a mixture of symbolic and neural approaches, e.g. how in Google Translate, they may tack on a logical rule that attempts to correct for gender biases in neurally-produced translations.<br />
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<footer style="font-size: 0.75rem;">
    <p>Made with <span class="heart">â™¥</span> using
        <a href="https://orgmode.org/">org-mode</a>.
        Source code is available
        <a href="https://github.com/ketan0/digital-laboratory">here</a>.
    </p>
</footer>
<script src="popper.min.js"></script>
<script src="tippy-bundle.umd.min.js"></script>
<script src="tooltips.js"></script>
<script src="setup-theme-switcher.js"></script>
<script src="insert-intext-citation.js"></script>
</div>
</body>
</html>