:PROPERTIES:
:ID:       22706d1f-6b5c-4c77-acc2-d8c222b395d5
:ROAM_REFS: https://arxiv.org/abs/2101.06046 @sauerCounterfactualGenerativeNetworks2021
:END:
#+title: Counterfactual Generative Networks

[[id:412cda14-f385-463d-9a7e-cd9ffe87c0a2][Neural networks like to "cheat"]] by using simple correlations that fail to generalize. E.g., image classifiers can learn spurious correlations with texture in the background, rather than the actual object's shape; a classifier might learn that "green grass background" => "cow classification."

This work [[id:b6fafba6-8e57-400d-962c-bf7cc892a41f][decomposes]] the image generation process into three independent causal mechanisms -- shape, texture, and background. Thus, one can generate "[[id:1f3f1a31-ff89-4c05-8c82-64888887f45e][counterfactual]] images" to improve OOD robustness, e.g. by placing a cow on a swimming pool background. Related: [[id:8e87ac0e-1002-474e-b4e7-778d908270a6][generative models]] [[id:1f3f1a31-ff89-4c05-8c82-64888887f45e][counterfactuals]]

* Problem setting:
We have images $\mathbf{x}$, and labels $y$. In generative modeling, it's common to assume that each $\mathbf{x}$ can be described by some lower-dimensional latent space $\mathbf{z}$ (e.g. color, shape, etc.) We'd like this latent [[id:c7ba956c-67ad-4b8e-9c7f-f18bc1b2b4ff][representation]] to be disentangled into several separate, semenatically meaningful factors, so we can control the influence of each on the classifier's decision. Usually in disentangled modeling, these factors are assumed to be statistically independent-- however, in practice this is a poor assumption. One rather contrived example is found in the colored MNIST dataset:

#+ATTR_HTML: :alt example digits in colored MNIST dataset.
[[file:colored_mnist.png]]

We might want to disentangle digit shape from color; however, in the train fold, all examples of the same digit are also the same color. (In the test fold, the colors are randomized.) Given this dataset, a "dumb" neural net might learn to do the simplest thing, which is to count how many pixels are a certain color; if a digit is red, it assumes it must be a 0, if it's green, a 1, and so on, completely ignoring the digit's shape.
* Structural Causal Models
An SCM $\mathfrak{C}$ is defined is a collection of $d$ structural assignments
$S_{j}:=f_{j}\left(\mathbf{P A}_{j}, U_{j}\right), \quad j=1, \ldots, d$
where each random variable $S_{j}$ is a function of its parents $\mathbf{P A}_{j} \subseteq\left\{S_{1}, \ldots, S_{d}\right\} \backslash\left\{S_{j}\right\}$ and a noise variable $U_{j}$. The noise variables $U_{1}, \ldots, U_{d}$ are jointly independent. The functions $f_{i}$ are
* Architecture
#+ATTR_HTML: :alt architecture diagram of the Counterfactual Generative Network (CGN.)
[[file:cgn_architecture.png]]
* Link
:PROPERTIES:
:HTML_CONTAINER_CLASS: no-display
:END:
@@html:<sup>@@[cite:@sauerCounterfactualGenerativeNetworks2021]@@html:</sup>@@
* Bibliography
#+print_bibliography:
